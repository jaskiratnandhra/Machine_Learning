{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Sumarization Using PorterStemmer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text :Peterson’s Algorithm is used to synchronize two processes. It uses two variables, a bool array flag of size 2 and an int variable turn to accomplish it. In the solution i represents the Consumer and j represents the Producer. Initially the flags are false. When a process wants to execute it’s critical section, it sets it’s flag to true and turn as the index of the other process. This means that the process wants to execute but it will allow the other process to run first. The process performs busy waiting until the other process has finished it’s own critical section. After this the current process enters it’s critical section and adds or removes a random number from the shared buffer. After completing the critical section, it sets it’s own flag to false, indication it does not wish to execute anymore.  The program runs for a fixed amount of time before exiting. This time can be changed by changing value of the macro RT.\n",
      "\n",
      "Summarized text is:\n",
      "\n",
      " Peterson’s Algorithm is used to synchronize two processes. Initially the flags are false. When a process wants to execute it’s critical section, it sets it’s flag to true and turn as the index of the other process. The process performs busy waiting until the other process has finished it’s own critical section.\n"
     ]
    }
   ],
   "source": [
    "# Implementation from https://dev.to/davidisrawi/build-a-quick-summarizer-with-python-and-nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text_str = input(\"Enter the text : \")\n",
    "\n",
    "\n",
    "def _create_frequency_table(text_string) -> dict:\n",
    "    \"\"\"\n",
    "    we create a dictionary for the word frequency table.\n",
    "    For this, we should only use the words that are not part of the stopWords array.\n",
    "    Removing stop words and making frequency table\n",
    "    Stemmer - an algorithm to bring words to its root word.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text_string)\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    return freqTable\n",
    "\n",
    "\n",
    "def _score_sentences(sentences, freqTable) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its words\n",
    "    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
    "        word_count_in_sentence_except_stop_words = 0\n",
    "        for wordValue in freqTable:\n",
    "            if wordValue in sentence.lower():\n",
    "                word_count_in_sentence_except_stop_words += 1\n",
    "                if sentence[:10] in sentenceValue:\n",
    "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
    "                else:\n",
    "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
    "\n",
    "        if sentence[:10] in sentenceValue:\n",
    "            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words\n",
    "\n",
    "        '''\n",
    "        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n",
    "        To solve this, we're dividing every sentence score by the number of words in the sentence.\n",
    "        \n",
    "        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n",
    "        the dictionary.\n",
    "        '''\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "\n",
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "\n",
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def run_summarization(text):\n",
    "    # 1 Create the word frequency table\n",
    "    freq_table = _create_frequency_table(text)\n",
    "\n",
    "    '''\n",
    "    We already have a sentence tokenizer, so we just need \n",
    "    to run the sent_tokenize() method to create the array of sentences.\n",
    "    '''\n",
    "\n",
    "    # 2 Tokenize the sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # 3 Important Algorithm: score the sentences\n",
    "    sentence_scores = _score_sentences(sentences, freq_table)\n",
    "\n",
    "    # 4 Find the threshold\n",
    "    threshold = _find_average_score(sentence_scores)\n",
    "\n",
    "    # 5 Important Algorithm: Generate the summary\n",
    "    summary = _generate_summary(sentences, sentence_scores, 1.0 * threshold)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = run_summarization(text_str)\n",
    "    print(\"\\nSummarized text is: \\n\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
